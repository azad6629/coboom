{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from barbar import Bar\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "import yaml\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.dataset_name = 'nih'\n",
    "        self.data_dir = '/workspace/DATASETS/NIH_Chest-Xray-14'\n",
    "        self.data_per = 1\n",
    "        self.mode       = 'fr'\n",
    "\n",
    "        self.base_method   = 'coboom'\n",
    "        self.pre_v         = 'v2'\n",
    "        self.pre_e         = 300\n",
    "        self.eval_e        = 230  \n",
    "        self.pre_b         = 64  \n",
    "        self.weight_dir    = f'/workspace/singh63/CoBoom/OLD/CoBoom/ckpt/{self.base_method}_{self.pre_v}/resnet18_NIH14_{self.pre_b}_{self.pre_e}'\n",
    "        self.pre_method    = f'resnet18_NIH14_{self.pre_b}_{self.pre_e}_{self.eval_e}'\n",
    "        self.backbone_path = os.path.join(self.weight_dir,self.pre_method+'.pth')\n",
    "        \n",
    "        self.save_path   = f'./{self.dataset_name}_ckpt/' + self.base_method+'_'+self.pre_v\n",
    "        self.model_path  = f'{self.save_path}/{self.pre_method}/{self.mode}/{self.data_per}/'\n",
    "        self.method_name = f'{self.dataset_name}_{self.pre_method}_{self.mode}_{self.data_per}'\n",
    "        \n",
    "        self.data_workers = 32\n",
    "        self.shuffle_dataset=True\n",
    "        self.random_seed=24\n",
    "\n",
    "        self.lr = 0.003\n",
    "        self.learning_rate_min = 0.000001\n",
    "                \n",
    "        self.batch_size = 128\n",
    "        self.test_batch_size = 1\n",
    "        self.num_classes = 15\n",
    "        self.resize_size=224\n",
    "        self.epochs = 300\n",
    "        \n",
    "        if self.data_per ==1:\n",
    "            self.nih_train_df ='./one_train_label_data.csv'\n",
    "        if self.data_per ==5:\n",
    "            self.nih_train_df ='./5_train_label_data.csv'\n",
    "        if self.data_per ==10:\n",
    "            self.nih_train_df ='./10_train_label_data.csv'\n",
    "        if self.data_per ==30:\n",
    "            self.nih_train_df ='./30_train_label_data.csv'\n",
    "        if self.data_per ==100:\n",
    "            self.nih_train_df ='./train_label_data.csv'\n",
    "        \n",
    "        self.nih_valid_df ='/workspace/DATASETS/NIH_Chest-Xray-14/test_label_data.csv'\n",
    " \n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "        os.makedirs(self.model_path, exist_ok=True)\n",
    "opt = Config()\n",
    "\n",
    "opt.backbone_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4400f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIHdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df,class_names,transform,):\n",
    "        \n",
    "        self.image_filepaths = df[\"filename\"].values \n",
    "        self.transform = transform\n",
    "        self.pathologies = class_names\n",
    "        self.pathologies = sorted(self.pathologies)\n",
    "        self.csv = df\n",
    "        \n",
    "        self.labels = []\n",
    "        for pathology in self.pathologies:\n",
    "            if pathology in self.csv.columns:\n",
    "                mask = self.csv[pathology]\n",
    "            self.labels.append(mask.values)\n",
    "            \n",
    "        self.labels = np.asarray(self.labels).T\n",
    "        self.labels = self.labels.astype(np.float32)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.image_filepaths[idx]\n",
    "        image = Image.open(img).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)   \n",
    "\n",
    "def get_transform(image_size,phase):\n",
    "    t_list = []\n",
    "    normalize = transforms.Normalize(mean=[0.0904, 0.2219, 0.4431],\n",
    "                                     std=[1.0070, 1.0294, 1.0249])\n",
    "    \n",
    "#     normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    if phase == \"train\":\n",
    "        t_list = [\n",
    "                transforms.Resize((image_size,image_size)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomGrayscale(p=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                normalize]\n",
    "        \n",
    "    if phase == \"val\":\n",
    "        t_list = [\n",
    "                transforms.Resize((image_size,image_size)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize]\n",
    "    \n",
    "    transform = transforms.Compose(t_list)\n",
    "    return transform\n",
    "\n",
    "def getnihchex14_dataset():\n",
    "    train_csv = opt.nih_train_df\n",
    "    valid_csv = opt.nih_valid_df\n",
    "    data_size = opt.data_per\n",
    "    \n",
    "    train_df  = pd.read_csv(train_csv)\n",
    "    valid_df  = pd.read_csv(valid_csv)\n",
    "    \n",
    "#     train_df = train_df.sample(frac=data_size)\n",
    "#     train_df.to_csv('/workspace/DATASETS/NIH_Chest-Xray-14/10_train_label_data.csv', index=False)\n",
    "    \n",
    "    \n",
    "    class_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', \n",
    "           'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', \n",
    "           'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "           \n",
    "    image_size = opt.resize_size\n",
    "    \n",
    "    train_transform  = get_transform(image_size, phase ='train')\n",
    "    valid_transform  = get_transform(image_size, phase ='val')\n",
    "    \n",
    "    \n",
    "    train_dataset = NIHdataset(train_df,class_names,transform=train_transform)\n",
    "    valid_dataset = NIHdataset(valid_df,class_names,transform=valid_transform)\n",
    "    \n",
    "    return train_dataset,valid_dataset\n",
    "\n",
    "def count_parameters(model):\n",
    "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return params/1000000\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "train_dataset,valid_dataset = getnihchex14_dataset()\n",
    "print(\"Train data length:\", len(train_dataset))\n",
    "print(\"Valid data length:\", len(valid_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=opt.batch_size,shuffle=True,num_workers=32,pin_memory=True)\n",
    "test_loader = DataLoader(valid_dataset,batch_size=opt.batch_size,shuffle=True,num_workers=32,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified LinearRegression class with improved feature handling\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        self.n_inputs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Identity()\n",
    "        \n",
    "        checkpoint = torch.load(opt.backbone_path, map_location=device)['online']\n",
    "        state_dict = {}\n",
    "        length = len(self.model.state_dict())\n",
    "        for name, param in zip(self.model.state_dict(), list(checkpoint.values())[:length]):\n",
    "            state_dict[name] = param\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self.n_inputs, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.linear(x)\n",
    "\n",
    "# Modified training loop with early stopping and proper initialization\n",
    "set_seed(opt.random_seed)\n",
    "logreg = LinearRegression(opt.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze backbone parameters\n",
    "if opt.mode == 'fr':\n",
    "    num_params = count_parameters(logreg.linear)\n",
    "    print(\"Total Parameter: \\t%d\" % (num_params*1000000))\n",
    "    for param in logreg.model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAUROC(dataGT, dataPRED):\n",
    "    # Computes area under ROC curve \n",
    "    outAUROC = []\n",
    "    datanpGT = dataGT.cpu().numpy()\n",
    "    datanpPRED = dataPRED.cpu().numpy()\n",
    "\n",
    "    for i in range(opt.num_classes):\n",
    "        try:\n",
    "            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return outAUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a4f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Train function properly separated from optimizer initialization\n",
    "def Train(regressor, dataloaderDownTrain, optimizer, scheduler, criterion):\n",
    "    # Track batch-wise loss for better monitoring\n",
    "    regressor.train()\n",
    "    losstrain = 0\n",
    "    \n",
    "    for batchID, (varInput, target) in enumerate(Bar(dataloaderDownTrain)):\n",
    "        varTarget = target.to(device)\n",
    "        varInput = varInput.to(device)\n",
    "        \n",
    "        # Apply modified forward pass with feature normalization\n",
    "        with torch.no_grad():\n",
    "            features = regressor.model(varInput)\n",
    "            \n",
    "        varOutput = regressor.linear(features)\n",
    "        \n",
    "        lossvalue = criterion(varOutput, varTarget)\n",
    "        \n",
    "        # Apply gradient clipping to prevent unstable updates\n",
    "        optimizer.zero_grad()\n",
    "        lossvalue.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(regressor.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        losstrain += lossvalue.item()\n",
    "    \n",
    "    # Step the scheduler based on epoch\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print current learning rate for monitoring\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Current LR: {current_lr:.6f}\")\n",
    "    \n",
    "    return losstrain / len(dataloaderDownTrain)\n",
    "\n",
    "# Modified Test function with improved evaluation\n",
    "def Test(regressor, dataLoaderTest):\n",
    "    cudnn.benchmark = True\n",
    "    outGT = torch.FloatTensor().to(device)\n",
    "    outPRED = torch.FloatTensor().to(device)\n",
    "    regressor.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (varInput, target) in enumerate(Bar(dataLoaderTest)):\n",
    "            target = target.to(device)\n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            outGT = outGT.to(device)\n",
    "            varInput = varInput.to(device)\n",
    "            \n",
    "            # Apply the same feature normalization as in training\n",
    "            features = regressor.model(varInput)\n",
    "            varOutput = regressor.linear(features)\n",
    "            \n",
    "            outPRED = torch.cat((outPRED, varOutput), 0)\n",
    "    \n",
    "    aurocIndividual = computeAUROC(outGT, outPRED)\n",
    "    aurocMean = np.array(aurocIndividual).mean()\n",
    "    return aurocIndividual, aurocMean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99afbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = logreg.to(device)\n",
    "\n",
    "# Initialize optimization components outside the train function\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    logreg.parameters(),\n",
    "    lr=opt.lr,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08,\n",
    "    weight_decay=1e-10  # Lower weight decay for faster convergence\n",
    ")\n",
    "\n",
    "# LR Scheduler with warm restarts\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,  # Restart every 10 epochs\n",
    "    T_mult=2,  # Double the restart interval after each restart\n",
    "    eta_min=opt.learning_rate_min\n",
    ")\n",
    "\n",
    "# Feature normalizer for consistent normalization\n",
    "feature_normalizer = torch.nn.LayerNorm(logreg.n_inputs).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc = 0.0\n",
    "count = 0\n",
    "patience = 10  # Early stopping patience\n",
    "plateau_threshold = 0.001  # Minimum improvement to consider progress\n",
    "\n",
    "# Initialize lists to track metrics\n",
    "train_losses = []\n",
    "valid_aucs = []\n",
    "\n",
    "for epoch in range(opt.epochs):\n",
    "    losst = Train(logreg, train_loader, optimizer, scheduler, criterion)\n",
    "    aurocIndividual, aurocMean = Test(logreg, test_loader)\n",
    "    \n",
    "    # Save metrics\n",
    "    train_losses.append(losst)\n",
    "    valid_aucs.append(aurocMean)\n",
    "    \n",
    "    print(\"Epoch: {},\".format(epoch), \"Train_loss: {:.3f},\".format(losst), \"Valid auc: {:.3f}\".format(aurocMean))\n",
    "    \n",
    "    with open(f'{opt.model_path}{opt.method_name}_logs.txt', 'a') as file:\n",
    "        file.write(str(epoch)+','+str(aurocMean)+','+str(losst)+'\\n')\n",
    "    \n",
    "    # Improved model saving logic with plateau detection\n",
    "    if aurocMean > best_auc + plateau_threshold:\n",
    "        torch.save(logreg.state_dict(), os.path.join(opt.model_path, f'{opt.method_name}.pth'))\n",
    "        print('auc increased ({:.3f} --> {:.3f}). Saving model ...'.format(best_auc, aurocMean))\n",
    "        best_auc = aurocMean\n",
    "        count = 0  # Reset counter\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "    \n",
    "    # Early stopping check\n",
    "    if count >= patience:\n",
    "        print(f\"No improvement for {patience} epochs. Early stopping.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea02776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves to visualize convergence\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(valid_aucs)\n",
    "plt.title('Validation AUC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AUC')\n",
    "plt.savefig(f'{opt.model_path}{opt.method_name}_training_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ac574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate\n",
    "log_checkpoint = torch.load(os.path.join(opt.model_path, f'{opt.method_name}.pth'), map_location=device)\n",
    "logreg.load_state_dict(log_checkpoint)\n",
    "logreg = logreg.to(device)\n",
    "\n",
    "aurocIndividual, aurocMean = Test(logreg, test_loader)\n",
    "print(f'Best validation AUC: {aurocMean:.2%}')\n",
    "print()\n",
    "\n",
    "formatted_aurocIndividual = [f'{auc:.2%}' for auc in aurocIndividual]\n",
    "\n",
    "class_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', \n",
    "           'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', \n",
    "           'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "\n",
    "for i in range(0, len(aurocIndividual)):\n",
    "    print(class_names[i], ' ', formatted_aurocIndividual[i])\n",
    "\n",
    "with open(f'{opt.model_path}{opt.method_name}_logs.txt', 'a') as file:\n",
    "    file.write('\\n\\n'+'Valid Mean AUC '+f'{aurocMean:.2%}'+'\\n\\n')    \n",
    "    for i in range(len(aurocIndividual)):\n",
    "        file.write(f'{class_names[i]} {formatted_aurocIndividual[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f699dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
